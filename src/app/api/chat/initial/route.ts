import { NextRequest, NextResponse } from 'next/server';
import { philosopherProfiles } from '@/lib/data/philosophers';

// ë°±ì—”ë“œ API URL
const BACKEND_API_URL = 'http://0.0.0.0:8000';

export async function POST(req: NextRequest) {
  try {
    // ìš”ì²­ ë°ì´í„° íŒŒì‹±
    const { philosopher, topic, context } = await req.json();

    console.log(`ğŸ’¬ Generating initial message for ${philosopher} on topic: ${topic}`);
    
    // í—¤ë”ì—ì„œ LLM ì„¤ì • í™•ì¸
    const llmProvider = req.headers.get('x-llm-provider') || 'openai';
    const llmModel = req.headers.get('x-llm-model') || '';

    // ì² í•™ì í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸°
    const profile = philosopherProfiles[philosopher];
    if (!profile) {
      console.error(`âŒ Philosopher profile not found for: ${philosopher}`);
      return NextResponse.json(
        { error: `Profile not found for philosopher: ${philosopher}` },
        { status: 400 }
      );
    }

    try {
      // ë°±ì—”ë“œ API í˜¸ì¶œ
      console.log(`ğŸ”„ Calling backend API at ${BACKEND_API_URL}/api/chat/generate`);
      
      const npcDescription = `Name: ${philosopher}
Role: Philosopher
Voice Style: ${profile.style}
Communication Style: balanced
Debate Approach: dialectical
Personality Traits: critical_thinking: 0.8, creativity: 0.7
Philosophical Background: ${profile.key_concepts.join(', ')}`;
      
      const backendResponse = await fetch(`${BACKEND_API_URL}/api/chat/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          npc_description: npcDescription,
          topic: topic,
          context: context || "",
          previous_dialogue: "",
          llm_provider: llmProvider,
          llm_model: llmModel || 'gpt-4o'
        }),
        // Next.js API ë¼ìš°íŠ¸ì—ì„œëŠ” https.Agentë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹¤ìŒ ì˜µì…˜ ì‚¬ìš©
        cache: 'no-store'
      });

      if (!backendResponse.ok) {
        throw new Error(`Backend API error: ${backendResponse.status}`);
      }

      const backendData = await backendResponse.json();
      const generatedText = backendData.response || backendData.text || backendData.message;
      
      console.log(`âœ… Generated initial message from backend for ${philosopher}`);
      return NextResponse.json({ text: generatedText });
    } catch (error) {
      console.error('âŒ Error calling backend API:', error);
      
      // ë°±ì—”ë“œ í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ
      const fallbackResponses = [
        `I find this topic of "${topic}" quite fascinating. What aspects of it interest you the most?`,
        `Let us explore "${topic}" together. What questions come to mind when you consider this subject?`,
        `The question of "${topic}" has intrigued philosophers for centuries. Where shall we begin our inquiry?`
      ];
      
      // ëœë¤ ì‘ë‹µ ì„ íƒ
      const randomResponse = fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)];
      console.log(`âš ï¸ Using fallback response due to backend error`);
      return NextResponse.json({ text: randomResponse });
    }
  } catch (error) {
    console.error('âŒ Error in initial chat handler:', error);
    return NextResponse.json(
      { error: "Failed to generate initial message" },
      { status: 500 }
    );
  }
} 